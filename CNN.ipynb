{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input,Lambda,Dense,Conv2D,Flatten,MaxPooling2D\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 16)      208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 32)      2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               25088500  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 25,100,046\n",
      "Trainable params: 25,100,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "classifier.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(224,224,3)))\n",
    "classifier.add(MaxPooling2D(pool_size=2))\n",
    "classifier.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=2))\n",
    "classifier.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "classifier.add(MaxPooling2D(pool_size=2))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(units=500,activation=\"relu\"))\n",
    "classifier.add(Dense(units=2,activation=\"softmax\"))\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=ImageDataGenerator(rescale=1/255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_data=ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 416 images belonging to 2 classes.\n",
      "Found 134 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train=train_data.flow_from_directory('Dataset/Train',target_size=(224,224),batch_size=32,class_mode='categorical')\n",
    "test=test_data.flow_from_directory('Dataset/Test',target_size=(224,224),batch_size=32,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "13/13 [==============================] - 15s 1s/step - loss: 0.9078 - accuracy: 0.5072 - val_loss: 0.6891 - val_accuracy: 0.5224\n",
      "Epoch 2/25\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.5854 - accuracy: 0.7019 - val_loss: 0.7687 - val_accuracy: 0.4328\n",
      "Epoch 3/25\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.4707 - accuracy: 0.7548 - val_loss: 1.3707 - val_accuracy: 0.2537\n",
      "Epoch 4/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.4293 - accuracy: 0.7740 - val_loss: 1.0561 - val_accuracy: 0.3134\n",
      "Epoch 5/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.3677 - accuracy: 0.8173 - val_loss: 1.7352 - val_accuracy: 0.3731\n",
      "Epoch 6/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.4161 - accuracy: 0.8053 - val_loss: 1.0210 - val_accuracy: 0.3881\n",
      "Epoch 7/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.3572 - accuracy: 0.8413 - val_loss: 0.8249 - val_accuracy: 0.4478\n",
      "Epoch 8/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.3314 - accuracy: 0.8558 - val_loss: 0.7299 - val_accuracy: 0.5597\n",
      "Epoch 9/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.2833 - accuracy: 0.8870 - val_loss: 0.9021 - val_accuracy: 0.5672\n",
      "Epoch 10/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.2578 - accuracy: 0.8966 - val_loss: 0.6188 - val_accuracy: 0.7164\n",
      "Epoch 11/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.2325 - accuracy: 0.9087 - val_loss: 0.8061 - val_accuracy: 0.5896\n",
      "Epoch 12/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.2331 - accuracy: 0.9014 - val_loss: 0.4456 - val_accuracy: 0.7388\n",
      "Epoch 13/25\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.1793 - accuracy: 0.9495 - val_loss: 0.5460 - val_accuracy: 0.7761\n",
      "Epoch 14/25\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.1403 - accuracy: 0.9567 - val_loss: 0.4375 - val_accuracy: 0.7612\n",
      "Epoch 15/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1396 - accuracy: 0.9543 - val_loss: 0.3130 - val_accuracy: 0.8657\n",
      "Epoch 16/25\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.1099 - accuracy: 0.9639 - val_loss: 0.3464 - val_accuracy: 0.8731\n",
      "Epoch 17/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1534 - accuracy: 0.9351 - val_loss: 0.5404 - val_accuracy: 0.7761\n",
      "Epoch 18/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1466 - accuracy: 0.9471 - val_loss: 0.3031 - val_accuracy: 0.8358\n",
      "Epoch 19/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1385 - accuracy: 0.9567 - val_loss: 0.2989 - val_accuracy: 0.8881\n",
      "Epoch 20/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1004 - accuracy: 0.9663 - val_loss: 0.2187 - val_accuracy: 0.9179\n",
      "Epoch 21/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1018 - accuracy: 0.9760 - val_loss: 0.3129 - val_accuracy: 0.8582\n",
      "Epoch 22/25\n",
      "13/13 [==============================] - 14s 1s/step - loss: 0.0999 - accuracy: 0.9736 - val_loss: 0.3037 - val_accuracy: 0.8582\n",
      "Epoch 23/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0904 - accuracy: 0.9639 - val_loss: 0.4432 - val_accuracy: 0.8284\n",
      "Epoch 24/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.1046 - accuracy: 0.9663 - val_loss: 0.3292 - val_accuracy: 0.8507\n",
      "Epoch 25/25\n",
      "13/13 [==============================] - 13s 1s/step - loss: 0.0568 - accuracy: 0.9856 - val_loss: 0.2005 - val_accuracy: 0.9030\n"
     ]
    }
   ],
   "source": [
    "run=classifier.fit_generator(train,validation_data=test,epochs=25,steps_per_epoch=len(train),validation_steps=len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.32626928e-02, 9.86737311e-01],\n",
       "       [9.99990702e-01, 9.33715000e-06],\n",
       "       [9.89001036e-01, 1.09989215e-02],\n",
       "       [7.30424821e-02, 9.26957548e-01],\n",
       "       [9.97921884e-01, 2.07816926e-03],\n",
       "       [9.98533845e-01, 1.46609952e-03],\n",
       "       [1.17759563e-01, 8.82240474e-01],\n",
       "       [1.37963239e-02, 9.86203671e-01],\n",
       "       [9.99229789e-01, 7.70237006e-04],\n",
       "       [9.99129355e-01, 8.70611577e-04],\n",
       "       [9.99999881e-01, 9.57641788e-08],\n",
       "       [9.99986172e-01, 1.38617133e-05],\n",
       "       [9.95923996e-01, 4.07599472e-03],\n",
       "       [1.94494858e-01, 8.05505216e-01],\n",
       "       [1.79851502e-01, 8.20148468e-01],\n",
       "       [9.98956561e-01, 1.04337593e-03],\n",
       "       [4.84593771e-02, 9.51540649e-01],\n",
       "       [2.38485318e-02, 9.76151407e-01],\n",
       "       [5.11108577e-01, 4.88891512e-01],\n",
       "       [8.50461483e-01, 1.49538517e-01],\n",
       "       [9.99038458e-01, 9.61532118e-04],\n",
       "       [7.97912478e-01, 2.02087596e-01],\n",
       "       [5.94582081e-01, 4.05417889e-01],\n",
       "       [9.99371707e-01, 6.28300593e-04],\n",
       "       [3.03741574e-01, 6.96258366e-01],\n",
       "       [9.99951363e-01, 4.86348326e-05],\n",
       "       [2.36479398e-02, 9.76352096e-01],\n",
       "       [4.22300130e-01, 5.77699900e-01],\n",
       "       [9.99998808e-01, 1.23890300e-06],\n",
       "       [2.94319633e-02, 9.70568061e-01],\n",
       "       [4.38054465e-02, 9.56194580e-01],\n",
       "       [9.99937415e-01, 6.26376423e-05],\n",
       "       [9.99998569e-01, 1.38938549e-06],\n",
       "       [9.98674870e-01, 1.32511195e-03],\n",
       "       [9.54187095e-01, 4.58129384e-02],\n",
       "       [4.73004907e-01, 5.26995122e-01],\n",
       "       [9.99267280e-01, 7.32730958e-04],\n",
       "       [3.78185771e-02, 9.62181389e-01],\n",
       "       [9.98424530e-01, 1.57548639e-03],\n",
       "       [9.99027252e-01, 9.72697278e-04],\n",
       "       [9.98240113e-01, 1.75986381e-03],\n",
       "       [7.41335332e-01, 2.58664697e-01],\n",
       "       [9.94394183e-01, 5.60586154e-03],\n",
       "       [1.00938296e-02, 9.89906132e-01],\n",
       "       [9.99934554e-01, 6.54983014e-05],\n",
       "       [3.19278762e-02, 9.68072116e-01],\n",
       "       [3.95635553e-02, 9.60436404e-01],\n",
       "       [9.98165786e-01, 1.83423015e-03],\n",
       "       [9.74589527e-01, 2.54104789e-02],\n",
       "       [3.22659314e-01, 6.77340686e-01],\n",
       "       [6.76374882e-02, 9.32362497e-01],\n",
       "       [9.97559905e-01, 2.44003907e-03],\n",
       "       [1.43464386e-01, 8.56535614e-01],\n",
       "       [9.98948753e-01, 1.05129532e-03],\n",
       "       [9.97289538e-01, 2.71046767e-03],\n",
       "       [7.79644608e-01, 2.20355406e-01],\n",
       "       [1.60249230e-02, 9.83975112e-01],\n",
       "       [2.86306851e-02, 9.71369267e-01],\n",
       "       [2.50581533e-01, 7.49418437e-01],\n",
       "       [9.97067511e-01, 2.93255574e-03],\n",
       "       [9.84486878e-01, 1.55130746e-02],\n",
       "       [9.99383926e-01, 6.16019941e-04],\n",
       "       [2.77537964e-02, 9.72246170e-01],\n",
       "       [6.18357398e-02, 9.38164294e-01],\n",
       "       [2.34833919e-02, 9.76516664e-01],\n",
       "       [8.93359538e-03, 9.91066396e-01],\n",
       "       [4.28135812e-01, 5.71864247e-01],\n",
       "       [4.78880573e-03, 9.95211184e-01],\n",
       "       [1.59541517e-01, 8.40458572e-01],\n",
       "       [9.99999404e-01, 6.48247976e-07],\n",
       "       [9.05537158e-02, 9.09446299e-01],\n",
       "       [9.90418732e-01, 9.58131999e-03],\n",
       "       [9.99994278e-01, 5.74972501e-06],\n",
       "       [9.99974370e-01, 2.56128751e-05],\n",
       "       [1.00000000e+00, 1.69686276e-09],\n",
       "       [3.86993662e-02, 9.61300611e-01],\n",
       "       [9.95991051e-01, 4.00894461e-03],\n",
       "       [9.97823954e-01, 2.17602588e-03],\n",
       "       [1.79792151e-01, 8.20207894e-01],\n",
       "       [2.56038327e-02, 9.74396169e-01],\n",
       "       [9.95653987e-01, 4.34599491e-03],\n",
       "       [9.97797489e-01, 2.20254809e-03],\n",
       "       [9.99920964e-01, 7.89783589e-05],\n",
       "       [9.99967217e-01, 3.27758244e-05],\n",
       "       [9.99970078e-01, 2.99161038e-05],\n",
       "       [8.00552785e-01, 1.99447259e-01],\n",
       "       [2.71968003e-02, 9.72803175e-01],\n",
       "       [9.99317884e-01, 6.82071666e-04],\n",
       "       [7.68366223e-03, 9.92316365e-01],\n",
       "       [9.99990940e-01, 9.05941215e-06],\n",
       "       [9.99742329e-01, 2.57620239e-04],\n",
       "       [3.56646806e-01, 6.43353164e-01],\n",
       "       [3.89432192e-01, 6.10567749e-01],\n",
       "       [9.88895893e-01, 1.11040752e-02],\n",
       "       [1.00000000e+00, 1.92785787e-09],\n",
       "       [9.99820292e-01, 1.79771567e-04],\n",
       "       [9.94047880e-01, 5.95211843e-03],\n",
       "       [9.96463001e-01, 3.53704207e-03],\n",
       "       [2.11736001e-02, 9.78826404e-01],\n",
       "       [4.54889089e-02, 9.54511106e-01],\n",
       "       [7.05524743e-01, 2.94475287e-01],\n",
       "       [4.08337303e-02, 9.59166229e-01],\n",
       "       [5.56238368e-03, 9.94437575e-01],\n",
       "       [9.98456955e-01, 1.54301431e-03],\n",
       "       [9.98606622e-01, 1.39342062e-03],\n",
       "       [2.86401976e-02, 9.71359849e-01],\n",
       "       [2.32094184e-01, 7.67905831e-01],\n",
       "       [9.99716103e-01, 2.83915288e-04],\n",
       "       [1.29110487e-02, 9.87088978e-01],\n",
       "       [9.99595702e-01, 4.04289458e-04],\n",
       "       [9.99450028e-01, 5.49957505e-04],\n",
       "       [9.93469357e-01, 6.53062388e-03],\n",
       "       [9.99853373e-01, 1.46606180e-04],\n",
       "       [9.70616341e-01, 2.93836389e-02],\n",
       "       [9.99774992e-01, 2.24959644e-04],\n",
       "       [9.99992371e-01, 7.61795445e-06],\n",
       "       [9.87342000e-03, 9.90126610e-01],\n",
       "       [9.99058664e-01, 9.41320905e-04],\n",
       "       [9.99908447e-01, 9.15385099e-05],\n",
       "       [9.98772562e-01, 1.22746115e-03],\n",
       "       [6.72364891e-01, 3.27635080e-01],\n",
       "       [4.69093174e-02, 9.53090727e-01],\n",
       "       [2.25602433e-01, 7.74397612e-01],\n",
       "       [1.00000000e+00, 1.55532192e-08],\n",
       "       [9.93820012e-01, 6.17997581e-03],\n",
       "       [9.98649061e-01, 1.35094125e-03],\n",
       "       [2.16895342e-02, 9.78310466e-01],\n",
       "       [3.70607227e-01, 6.29392803e-01],\n",
       "       [1.43541964e-02, 9.85645831e-01],\n",
       "       [7.72806108e-01, 2.27193922e-01],\n",
       "       [9.99999881e-01, 7.32176915e-08],\n",
       "       [8.36664200e-01, 1.63335845e-01],\n",
       "       [1.80605724e-02, 9.81939375e-01],\n",
       "       [4.94206557e-03, 9.95057940e-01]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=classifier.predict(test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=np.argmax(pred,axis=1)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=load_model('cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "img=image.load_img('Dataset/Test/Parasite/C39P4thinF_original_IMG_20150622_105554_cell_10.png',target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=image.img_to_array(img)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x/225\n",
    "x=np.expand_dims(x,axis=0)\n",
    "img_data=preprocess_input(x)\n",
    "img_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.argmax(classifier.predict(img_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infected\n"
     ]
    }
   ],
   "source": [
    "if(p==1):\n",
    "    print(\"Uninfected\")\n",
    "else:\n",
    "    print(\"Infected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
